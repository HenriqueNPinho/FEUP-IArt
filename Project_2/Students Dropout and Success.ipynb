{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning - Artificial Intelligence\n",
    "\n",
    "## Students' Dropout and Success\n",
    "\n",
    "### Notebook by Henrique Pinho, João Lopes and Luís Marques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Machine learning is an application of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. \n",
    "\n",
    "In this notebook, we will be using Supervised learning to predict if a student graduates or dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required libraries\n",
    "\n",
    "[[ go back to the top ]](#Table-of-contents)\n",
    "\n",
    "If you don't have Python on your computer, you can use the [Anaconda Python distribution](http://continuum.io/downloads) to install most of the Python packages you need. Anaconda provides a simple double-click installer for your convenience.\n",
    "\n",
    "This notebook uses several Python packages that come standard with the Anaconda Python distribution. The primary libraries that we'll be using are:\n",
    "\n",
    "* **NumPy**: Provides a fast numerical array structure and helper functions.\n",
    "* **pandas**: Provides a DataFrame structure to store data in memory and work with it easily and efficiently.\n",
    "* **scikit-learn**: The essential Machine Learning package in Python.\n",
    "* **matplotlib**: Basic plotting library in Python; most other Python plotting libraries are built on top of it.\n",
    "* **Seaborn**: Advanced statistical plotting library.\n",
    "\n",
    "To make sure you have all of the packages you need, install them with `conda`:\n",
    "\n",
    "    conda install numpy pandas scikit-learn matplotlib seaborn\n",
    "    \n",
    "    conda install -c conda-forge watermark\n",
    "\n",
    "`conda` may ask you to update some of them if you don't have the most recent version. Allow it to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpt\n",
    "import sklearn as sk\n",
    "import seaborn as sb\n",
    "import time\n",
    "from sklearn import tree\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the data\n",
    "\n",
    "\n",
    "The next step is to look at the data we're working with. Even curated data sets from the government can have errors in them, and it's vital that we spot these errors before investing too much time in our analysis.\n",
    "\n",
    "Generally, we're looking to answer the following questions:\n",
    "\n",
    "* Is there anything wrong with the data?\n",
    "* Are there any quirks with the data?\n",
    "* Do I need to fix or remove any of the data?\n",
    "\n",
    "Let's start by reading the data into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance\\t</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>Father's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.74</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>8014</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marital status  Application mode  Application order  Course  \\\n",
       "0               1                17                  5     171   \n",
       "1               1                15                  1    9254   \n",
       "2               1                 1                  5    9070   \n",
       "3               1                17                  2    9773   \n",
       "4               2                39                  1    8014   \n",
       "\n",
       "   Daytime/evening attendance\\t  Previous qualification  \\\n",
       "0                             1                       1   \n",
       "1                             1                       1   \n",
       "2                             1                       1   \n",
       "3                             1                       1   \n",
       "4                             0                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                           122.0            1                      19   \n",
       "1                           160.0            1                       1   \n",
       "2                           122.0            1                      37   \n",
       "3                           122.0            1                      38   \n",
       "4                           100.0            1                      37   \n",
       "\n",
       "   Father's qualification  ...  Curricular units 2nd sem (credited)  \\\n",
       "0                      12  ...                                    0   \n",
       "1                       3  ...                                    0   \n",
       "2                      37  ...                                    0   \n",
       "3                      37  ...                                    0   \n",
       "4                      38  ...                                    0   \n",
       "\n",
       "   Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0   \n",
       "1                                    6   \n",
       "2                                    6   \n",
       "3                                    6   \n",
       "4                                    6   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       0   \n",
       "1                                       6   \n",
       "2                                       0   \n",
       "3                                      10   \n",
       "4                                       6   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    0                          0.000000   \n",
       "1                                    6                         13.666667   \n",
       "2                                    0                          0.000000   \n",
       "3                                    5                         12.400000   \n",
       "4                                    6                         13.000000   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               10.8   \n",
       "1                                               0               13.9   \n",
       "2                                               0               10.8   \n",
       "3                                               0                9.4   \n",
       "4                                               0               13.9   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             1.4  1.74   Dropout  \n",
       "1            -0.3  0.79  Graduate  \n",
       "2             1.4  1.74   Dropout  \n",
       "3            -0.8 -3.12  Graduate  \n",
       "4            -0.3  0.79  Graduate  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data = pd.read_csv('data.csv', delimiter=';')\n",
    "student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we split the data in the three targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enrolled = student_data[student_data.Target == \"Enrolled\"].drop(columns=['Target'])\n",
    "graduated = student_data[student_data.Target == \"Graduate\"].drop(columns=['Target'])\n",
    "dropout = student_data[student_data.Target == \"Dropout\"].drop(columns=['Target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Number of students per Target')\n",
    "plt.bar(['Graduated', 'Enrolled', 'Dropout'], [len(graduated), len(enrolled), len(dropout)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will focus only on the success or dropout of the students. All rows with target Enrolled will be left out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_clean = student_data.drop(student_data[student_data['Target'] == 'Enrolled'].index, inplace=False)\n",
    "student_data_clean.describe()\n",
    "#student_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project our focus is in the students that graduate or dropout, so the students that are enrolled will be left out from this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graduate_data = student_data_clean[student_data_clean.Target == 'Graduate']\n",
    "graduate_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_data = student_data_clean[student_data_clean.Target == 'Dropout']\n",
    "dropout_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is more graduated student then to balance the dataset a Stratified Sampling was applyed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graduate_data_1 = graduate_data.iloc[:500,:]\n",
    "graduate_data_2 = graduate_data.iloc[500:1000,:]\n",
    "graduate_data_3 = graduate_data.iloc[1000:1500,:]\n",
    "graduate_data_4 = graduate_data.iloc[1500:,:]\n",
    "\n",
    "graduate_data_1_sample = graduate_data_1.sample(n=350, axis=0)\n",
    "graduate_data_2_sample = graduate_data_2.sample(n=350, axis=0)\n",
    "graduate_data_3_sample = graduate_data_3.sample(n=350, axis=0)\n",
    "graduate_data_4_sample = graduate_data_4.sample(n=350, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "graduate_sample = pd.concat([graduate_data_1_sample, graduate_data_2_sample, graduate_data_3_sample, graduate_data_4_sample])\n",
    "graduate_sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_clean = pd.concat([graduate_sample, dropout_data])\n",
    "student_data_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line tells the notebook to show plots inside of the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "#sb.pairplot(student_data_clean.sample(100), hue='Target')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_corr = student_data_clean.corr()\n",
    "mask = np.zeros_like(student_data_corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "plt.figure(figsize=(15,15))\n",
    "with sb.axes_style(\"white\"):\n",
    "    ax = sb.heatmap(student_data_corr, linewidths=0.1, cmap=\"YlGnBu\", annot=True, square=True, mask=mask, fmt='.2f', annot_kws={\"size\": 6}, vmax=1, vmin=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this correlation matrix we can exctract features that are strongly correlated with eachother. Values with an absolute value of more than 0.9 which is our criteria for correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_corr = student_data_clean.corr().abs()\n",
    "\n",
    "upper = student_data_corr.where(np.triu(np.ones(student_data_corr.shape), k=1).astype(bool))\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "\n",
    "old_n_columns = len(student_data_clean.columns)\n",
    "\n",
    "student_data_clean.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "print('Dropped ' + str(old_n_columns-len(student_data_clean.columns)) + ' columns')\n",
    "student_data_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliar function to retrieve the inputs and labels from dataset provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_labels(dataset, scaler=None):\n",
    "    all_inputs = dataset.drop('Target', axis=1)\n",
    "    all_labels = dataset['Target']\n",
    "    \n",
    "    if scaler != None:\n",
    "        scaler = scaler.fit(all_inputs)\n",
    "        all_inputs = scaler.transform(all_inputs)\n",
    "\n",
    "    return all_inputs, all_labels\n",
    "        \n",
    "all_inputs, all_labels = get_inputs_labels(student_data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliar function to perform parameter tunning with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def tune_model(dataset, model_instance, parameter_grid, cross_validation=StratifiedKFold(n_splits=10), scaler=None, oversample=False): \n",
    "    all_inputs, all_labels = get_inputs_labels(dataset, scaler)\n",
    "    \n",
    "    if oversample:\n",
    "        steps = [('sampling', SMOTE()), ('model', model_instance)]\n",
    "        model_instance = Pipeline(steps=steps)\n",
    "\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model_instance,\n",
    "        param_grid=parameter_grid,\n",
    "        cv=cross_validation,\n",
    "        scoring=\"f1_weighted\"\n",
    "    )\n",
    "\n",
    "    grid_search.fit(all_inputs, all_labels)\n",
    "    print('Best score: {}'.format(grid_search.best_score_))\n",
    "    print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n",
    "    grid_search.best_estimator_\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def measure_time(dataset, model_instance, params, scaler=None, oversample=False):\n",
    "    all_inputs, all_labels = get_inputs_labels(dataset, scaler)\n",
    "\n",
    "    if oversample:\n",
    "        steps = [('sampling', SMOTE()), ('model', model_instance)]\n",
    "        model_instance = Pipeline(steps=steps)\n",
    "    model_instance.set_params(**params)\n",
    "\n",
    "    (training_inputs,\n",
    "    testing_inputs,\n",
    "    training_classes,\n",
    "    testing_classes) = train_test_split(all_inputs, all_labels, test_size=0.25, random_state=1)\n",
    "    \n",
    "    start = time.time()\n",
    "    model_instance.fit(training_inputs, training_classes)\n",
    "    end = time.time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "\n",
    "\n",
    "parameters = {'criterion': ['gini', 'entropy'],\n",
    "                'splitter': ['best', 'random'],\n",
    "                'max_depth': [8],\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "decision_tree_w_parameters = GridSearchCV(decision_tree_classifier,\n",
    "                            param_grid=parameters)\n",
    "\n",
    "\n",
    "decision_tree_w_parameters.fit(training_inputs, training_classes)\n",
    "\n",
    "with open('decision_tree.dot', 'w') as out_file:\n",
    "    out_file = tree.export_graphviz(decision_tree_w_parameters.best_estimator_ , out_file=out_file)\n",
    "\n",
    "decision_tree_w_parameters.score(testing_inputs, testing_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parameter_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': range(1, 9),\n",
    "    'max_features': range(1, 9)\n",
    "}\n",
    "\n",
    "dt_original = tune_model(student_data, DecisionTreeClassifier(), parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tune_model(student_data_clean, DecisionTreeClassifier(), parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'model__criterion': ['gini', 'entropy'],\n",
    "    'model__splitter': ['best', 'random'],\n",
    "    'model__max_depth': range(1, 7),\n",
    "    'model__max_features': range(1, 7)\n",
    "}\n",
    "\n",
    "dt_os_fs = tune_model(student_data_clean, DecisionTreeClassifier(), parameter_grid, oversample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_inputs_labels(student_data_clean)\n",
    "\n",
    "# Without standardizing the data:\n",
    "svc = SVC()\n",
    "\n",
    "# cross_val_score returns a list of the scores, which we can visualize\n",
    "# to get a reasonable estimate of our classifier's performance\n",
    "cv_scores = cross_val_score(svc, X, y, cv=10)\n",
    "\n",
    "plt.hist(cv_scores)\n",
    "plt.title('Average score: {}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data:\n",
    "standardized_X, y = get_inputs_labels(student_data_clean, scaler = StandardScaler())\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "# cross_val_score returns a list of the scores, which we can visualize\n",
    "# to get a reasonable estimate of our classifier's performance\n",
    "cv_scores = cross_val_score(svc, standardized_X, y, cv=10)\n",
    "plt.hist(cv_scores)\n",
    "plt.title('Average score: {}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing both histograms, it can be easily concluded that the standardization is really necessary and produces better and more consistent results.\n",
    "\n",
    "Still the cross validation scores vary a lot based on the training data chosen. Therefore we should do some parameter tuning to see what the best parameters are for our dataset that don't overfit the data. This can be achieved by a GridSearch. This will be addressed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'C': [1, 10, 50], \n",
    "    'gamma': [0.001, 0.0001],\n",
    "    'kernel': ['linear', 'poly', 'rbf']\n",
    "    #'kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# No oversampling / No feature selection\n",
    "svc_original = tune_model(student_data, SVC(), parameter_grid, scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No oversampling / Feature selection\n",
    "svc = tune_model(student_data_clean, SVC(), parameter_grid, scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'model__C': [1, 10, 50], \n",
    "    'model__gamma': [0.001, 0.0001],\n",
    "    # 'kernel': ['linear', 'poly', 'rbf']\n",
    "    'model__kernel': ['linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Oversampling / Feature Selection\n",
    "svc_os_fs = tune_model(student_data_clean, SVC(), parameter_grid, scaler=StandardScaler(), oversample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest neighbours (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without standardizing the data\n",
    "\n",
    "X, y = get_inputs_labels(student_data_clean)\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "\n",
    "# cross_val_score returns a list of the scores, which we can visualize\n",
    "# to get a reasonable estimate of our classifier's performance\n",
    "cv_scores = cross_val_score(knn, X, y, cv=10)\n",
    "plt.hist(cv_scores)\n",
    "plt.title('Average score: {}'.format(np.mean(cv_scores)))\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data\n",
    "standardized_X, y = get_inputs_labels(student_data_clean, scaler=StandardScaler())\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "\n",
    "cv_scores = cross_val_score(knn, standardized_X, y, cv=10)\n",
    "plt.hist(cv_scores)\n",
    "plt.title('Average score: {}'.format(np.mean(cv_scores)))\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid =  {\n",
    "    'n_neighbors':[4,5,6,7,10,15],\n",
    "    'leaf_size':[5, 10, 15, 20, 50, 100],\n",
    "    'n_jobs':[-1],\n",
    "    'algorithm':['auto']\n",
    "}\n",
    "\n",
    "# No oversampling / No feature selection\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn_original = tune_model(student_data, knn, parameter_grid, scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No oversampling / Feature selection\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn = tune_model(student_data_clean, knn, parameter_grid, scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'model__n_neighbors':[4,5,6,7,10,15],\n",
    "    'model__leaf_size':[5, 10, 15, 20, 50, 100],\n",
    "    'model__n_jobs':[-1],\n",
    "    'model__algorithm':['auto']\n",
    "}\n",
    "\n",
    "# Oversampling / Feature Selection\n",
    "knn_os_fs = tune_model(student_data_clean, neighbors.KNeighborsClassifier(), parameter_grid, scaler=StandardScaler(), oversample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parameter_grid = {}\n",
    "\n",
    "# No oversampling / No feature selection\n",
    "nb_original = tune_model(student_data, GaussianNB(), parameter_grid, scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No oversampling / Feature selection\n",
    "nb = tune_model(student_data_clean, GaussianNB(), parameter_grid, scaler=StandardScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {}\n",
    "\n",
    "# Oversampling / Feature Selection\n",
    "nb_os_fs = tune_model(student_data_clean, GaussianNB(), parameter_grid, scaler=StandardScaler(), oversample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'n_jobs': [-1], #Use all cores\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# No oversampling / No feature selection\n",
    "rfc_original = tune_model(student_data, RandomForestClassifier(), parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No oversampling / Feature selection\n",
    "rfc = tune_model(student_data_clean, RandomForestClassifier(), parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "    'model__n_estimators': [10, 50, 100, 200],\n",
    "    'model__max_depth': [5, 10, 15],\n",
    "    'model__n_jobs': [-1], #Use all cores\n",
    "    'model__criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Oversampling / Feature Selection\n",
    "rfc_os_fs = tune_model(student_data_clean, RandomForestClassifier(), parameter_grid, oversample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"Decision Tree\" : [dt_original, dt, dt_os_fs],\n",
    "    \"SVC\" : [svc_original, svc, svc_os_fs],\n",
    "    \"K-nearest Neighbours\" : [knn_original, knn, knn_os_fs],\n",
    "    \"Naive Bayes\" : [nb_original, nb, nb_os_fs],\n",
    "    \"Random Forest\" : [rfc_original, rfc, rfc_os_fs]\n",
    "}\n",
    "\n",
    "labels = [\"Original Data\",\"Modified Data\", \"Oversampled Modified Data\"]\n",
    "\n",
    "ind = np.arange(5)\n",
    "\n",
    "plt.figure(figsize=(11,11))\n",
    "plt.bar(ind, [i[0].best_score_ for i in scores.values()], 0.2)\n",
    "ax = plt.bar(ind + 0.2, [i[1].best_score_ for i in scores.values()], 0.2)\n",
    "ax = plt.bar(ind + 0.4, [i[2].best_score_ for i in scores.values()], 0.2)\n",
    "plt.xticks(ind, scores.keys())\n",
    "plt.legend(labels,loc=2)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = {\n",
    "    \"Decision Tree\" : [\n",
    "        measure_time(student_data, DecisionTreeClassifier(), dt_original.best_params_),\n",
    "        measure_time(student_data_clean, DecisionTreeClassifier(), dt.best_params_),\n",
    "        measure_time(student_data_clean, DecisionTreeClassifier(), dt_os_fs.best_params_, oversample=True)\n",
    "    ],\n",
    "    \"SVC\" : [\n",
    "        measure_time(student_data, SVC(), svc_original.best_params_, scaler=StandardScaler()),\n",
    "        measure_time(student_data_clean, SVC(), svc.best_params_, scaler=StandardScaler()),\n",
    "        measure_time(student_data_clean, SVC(), svc_os_fs.best_params_, oversample=True, scaler=StandardScaler())\n",
    "    ],\n",
    "    \"K-nearest Neighbours\" : [\n",
    "        measure_time(student_data, neighbors.KNeighborsClassifier(), knn_original.best_params_, scaler=StandardScaler()),\n",
    "        measure_time(student_data_clean, neighbors.KNeighborsClassifier(), knn.best_params_, scaler=StandardScaler()),\n",
    "        measure_time(student_data_clean, neighbors.KNeighborsClassifier(), knn_os_fs.best_params_, oversample=True, scaler=StandardScaler())\n",
    "    ],\n",
    "    \"Naive Bayes\" : [\n",
    "        measure_time(student_data, GaussianNB(), nb_original.best_params_, scaler=StandardScaler()),\n",
    "        measure_time(student_data_clean, GaussianNB(), nb.best_params_, scaler=StandardScaler()),\n",
    "        measure_time(student_data_clean, GaussianNB(), nb_os_fs.best_params_, oversample=True, scaler=StandardScaler())\n",
    "    ],\n",
    "    \"Random Forest\" : [\n",
    "        measure_time(student_data, RandomForestClassifier(), rfc_original.best_params_),\n",
    "        measure_time(student_data_clean, RandomForestClassifier(), rfc.best_params_),\n",
    "        measure_time(student_data_clean, RandomForestClassifier(), rfc_os_fs.best_params_, oversample=True)\n",
    "    ]\n",
    "}\n",
    "\n",
    "labels = [\"No oversampling/No feature selection\",\"No oversampling/Feature selection\", \"Oversampling/Feature selection\"]\n",
    "\n",
    "ind = np.arange(5)\n",
    "\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.bar(ind, [i[0] for i in times.values()], 0.2)\n",
    "ax = plt.bar(ind + 0.2, [i[1] for i in times.values()], 0.2)\n",
    "ax = plt.bar(ind + 0.4, [i[2] for i in times.values()], 0.2)\n",
    "plt.xticks(ind, times.keys())\n",
    "plt.legend(labels,loc=1)\n",
    "\n",
    "# plt.ylim(0.7, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed work was to test and compare different Supervised Machine Learning models for classification of the **Students' Success or Dropout** dataset. The tested models were **Decision Tree**, **Support Vector Machines**, **K-nearest Neighbours**, **Naive Bayes** and **Random Forest**.\n",
    "\n",
    "After some exploratory data analysis we decided to drop some features based on their correlation with each other. This proved to be only effective in the **Naive Bayes** and **Random Forest Classifiers**.\n",
    "\n",
    "To evaluate each model and choose the best parameters for each one, we used SKLearn's GridSearchCV to test different set of parameters. To score the models we used f1 wighted score. We also tried combining oversampling with and without feature selection. Looking at the benchmarks we can conclude that oversampling does not improve the scores on our models while increasing significantly the training time.\n",
    "\n",
    "In terms of scoring, it can be concluded that the best models for our classification problem is the **Support Vector Machine**, followed closely by the **K-nearest Neighbors**. However when we take a look at the time needed to train each model, the **Support Vector Machine** takes much longer than **K-nearest Neighbours**, making **K-nearest neighbours** the best model overall. This appears to be related to the fact that **K-nearest Neighbours** can be trained with the flag n_jobs=-1 which makes it use all the cores in the CPU while **Support Vector Machine** does not support this option."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
